{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DCASE2020_SEQUENTIAL_LSTM_AE_FAN.ipynb","provenance":[],"collapsed_sections":["UAsyVUTblaPA","TEtzqLn2liwP"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Rs9iIa5OlJth"},"source":["# IMPORT AND DATA LOADING"]},{"cell_type":"code","metadata":{"id":"WDG8iAV_W2fa"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m9uFgr4mYC5v"},"source":["# import necessari\n","import librosa\n","import numpy\n","import sys\n","import os\n","import glob\n","import itertools\n","import re\n","import pickle\n","import keras\n","import tensorflow as tf\n","import tensorflow.keras.models\n","import tensorflow.keras.backend as K\n","import keras.optimizers\n","from tensorflow.keras.constraints import max_norm\n","from keras import Model\n","from keras.layers import LSTM, RepeatVector, TimeDistributed, Dense, Dropout\n","from tqdm import tqdm\n","from itertools import groupby\n","from keras.utils import to_categorical\n","from sklearn import metrics\n","from sklearn.model_selection import train_test_split\n","\n","# costanti \n","ALPHA = 0.75\n","N_MELS = 128\n","HOP_LENGTH = 512\n","N_FFT = 1024\n","POWER = 2.0\n","FRAME_NUMS = 313\n","FRAMES = 10\n","VAL = 0.05\n","\n","# FEATURES EXTRACTION\n","\n","# Loading da Google Drive\n","train_data = numpy.load(\"/content/drive/MyDrive/DCASE_DATA_EXTRACTED/train/training_fan.npy\")\n","grouped_list_by_machine_id = pickle.load( open( \"/content/drive/MyDrive/DCASE_DATA_EXTRACTED/train/training_fan_grouped_list.npy\", \"rb\" ) )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uDq3dIgZxVEC","outputId":"c009c3f6-8d38-450f-bca5-2c19b47a2aa0"},"source":["# GENERAZIONE DELLE LABELS\n","# One-hot encoding\n","label = []\n","choices = []\n","for i in range(0, len(grouped_list_by_machine_id)):\n","  for j in range(0, len(grouped_list_by_machine_id[i])):\n","    machine_id = grouped_list_by_machine_id[i][j].split('/')[7].split('_')[2]\n","    #print(grouped_list_by_machine_id[i][j].split('/')[7])\n","    random_choice = numpy.random.choice([\"match\", \"non_match\"], p = [ALPHA, 1-ALPHA]) \n","\n","    if machine_id == '00':\n","      if random_choice == \"match\":\n","        to_append = [1,0,0,0]\n","      else: \n","        not_match_label = numpy.random.choice([1, 2, 3]) \n","        if not_match_label == 1:\n","          to_append = [0,1,0,0]\n","        elif not_match_label == 2:\n","          to_append = [0,0,1,0]\n","        else: \n","          to_append = [0,0,0,1]\n","\n","    elif machine_id == '02': \n","      if random_choice == \"match\":\n","        to_append = [0,1,0,0]\n","      else: \n","        not_match_label = numpy.random.choice( [ 1, 2, 3] ) \n","        if not_match_label == 1:\n","          to_append = [1,0,0,0]\n","        elif not_match_label == 2:\n","          to_append = [0,0,1,0]\n","        else: \n","          to_append = [0,0,0,1]\n","\n","    elif machine_id == \"04\":\n","      if random_choice == \"match\":\n","        to_append = [0,0,1,0]\n","      else: \n","        not_match_label = numpy.random.choice( [ 1, 2, 3] ) \n","        if not_match_label == 1:\n","          to_append = [1,0,0,0]\n","        elif not_match_label == 2:\n","          to_append = [0,1,0,0]\n","        else: \n","          to_append = [0,0,0,1]\n","\n","    elif machine_id == \"06\":\n","      if random_choice == \"match\":\n","        to_append = [0,0,0,1]\n","      else: \n","        not_match_label = numpy.random.choice( [ 1, 2, 3] ) \n","        if not_match_label == 1:\n","          to_append = [1,0,0,0]\n","        elif not_match_label == 2:\n","          to_append = [0,1,0,0]\n","        else: \n","          to_append = [0,0,1,0]\n","    \n","    label.append(to_append) # Append della label associata a ciascuno spettrogramma\n","    choices.append(random_choice) # Append della choice utilizzata per associare la label\n","                                  # La choice sarà utile in fase di addestramento per capire che tipo di loss calcolare\n","\n","# Trasformazione in numpy.array     \n","label = numpy.asarray(label)\n","choices = numpy.asarray(choices)\n","print(label.shape)\n","print(choices.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(3675, 4)\n","(3675,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"czuXNBN8CelQ","outputId":"a57603cc-c223-4390-ee69-5a80460c4825"},"source":["print(len(grouped_list_by_machine_id[0]))\n","print(len(grouped_list_by_machine_id[1]))\n","print(len(grouped_list_by_machine_id[2]))\n","print(len(grouped_list_by_machine_id[3]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["911\n","916\n","933\n","915\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oQagajQlV65x","outputId":"9520222f-f5d1-488a-d56c-73c9232dffec"},"source":["# Estrazione spettrogrammi divisi per ID\n","id_00 = train_data[0:911]\n","label_00 = label[0:911]\n","choices_00 = choices[0:911]\n","\n","id_02 = train_data[911:1827]\n","label_02 = label[911:1827]\n","choices_02 = choices[911:1827]\n","\n","id_04 = train_data[1827:2760]\n","label_04 = label[1827:2760]\n","choices_04 = choices[1827:2760]\n","\n","id_06 = train_data[2760:3675]\n","label_06 = label[2760:3675]\n","choices_06 = choices[2760:3675]\n","\n","id_00_training, \\\n","id_00_validation, \\\n","label_00_train, \\\n","label_00_validation, \\\n","choices_00_train, \\\n","choices_00_validation = train_test_split(id_00, label_00, choices_00, test_size=VAL, random_state=42)\n","\n","id_02_training, \\\n","id_02_validation, \\\n","label_02_train, \\\n","label_02_validation, \\\n","choices_02_train, \\\n","choices_02_validation = train_test_split(id_02, label_02, choices_02, test_size=VAL, random_state=42)\n","\n","id_04_training, \\\n","id_04_validation, \\\n","label_04_train, \\\n","label_04_validation, \\\n","choices_04_train, \\\n","choices_04_validation = train_test_split(id_04, label_04, choices_04, test_size=VAL, random_state=42)\n","\n","id_06_training, \\\n","id_06_validation, \\\n","label_06_train, \\\n","label_06_validation, \\\n","choices_06_train, \\\n","choices_06_validation = train_test_split(id_06, label_06, choices_06, test_size=VAL, random_state=42)\n","\n","# Normalization ID_00\n","id_00_norm = numpy.empty_like(id_00_training)\n","mean_00 = numpy.mean(id_00_training)\n","std_00 = numpy.std(id_00_training)\n","id_00_norm = (id_00_training - mean_00) / (std_00)\n","id_00_norm_validation = (id_00_validation - mean_00) / (std_00)\n","\n","# Normalization ID_02\n","id_02_norm = numpy.empty_like(id_02_training)\n","mean_02 = numpy.mean(id_02_training)\n","std_02 = numpy.std(id_02_training)\n","id_02_norm = (id_02_training - mean_02) / (std_02)\n","id_02_norm_validation = (id_02_validation - mean_02) / (std_02)\n","\n","# Normalization ID_04\n","id_04_norm = numpy.empty_like(id_04_training)\n","mean_04 = numpy.mean(id_04_training)\n","std_04 = numpy.std(id_04_training)\n","id_04_norm = (id_04_training - mean_04) / (std_04)\n","id_04_norm_validation = (id_04_validation - mean_04) / (std_04)\n","\n","# Normalization ID_06\n","id_06_norm = numpy.empty_like(id_06_training)\n","mean_06 = numpy.mean(id_06_training)\n","std_06 = numpy.std(id_06_training)\n","id_06_norm = (id_06_training - mean_06) / (std_06)\n","id_06_norm_validation = (id_06_validation - mean_06) / (std_06)\n","\n","print(\"==== DATA ====\")\n","total_training = numpy.concatenate([id_00_norm, id_02_norm, id_04_norm, id_06_norm])\n","print(total_training.shape)\n","total_validation = numpy.concatenate([id_00_norm_validation, id_02_norm_validation, id_04_norm_validation, id_06_norm_validation])\n","print(total_validation.shape)\n","\n","print(\"==== LABELS ====\")\n","total_training_label = numpy.concatenate([label_00_train, label_02_train, label_04_train, label_06_train])\n","print(total_training_label.shape)\n","total_validation_label = numpy.concatenate([label_00_validation, label_02_validation, label_04_validation, label_06_validation])\n","print(total_validation_label.shape)\n","\n","print(\"==== CHOICES ====\")\n","total_training_choices = numpy.concatenate([choices_00_train, choices_02_train, choices_04_train, choices_06_train])\n","print(total_training_choices.shape)\n","total_validation_choices = numpy.concatenate([choices_00_validation, choices_02_validation, choices_04_validation, choices_06_validation])\n","print(total_validation_choices.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["==== DATA ====\n","(3490, 128, 313)\n","(185, 128, 313)\n","==== LABELS ====\n","(3490, 4)\n","(185, 4)\n","==== CHOICES ====\n","(3490,)\n","(185,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1_KQ1vZ2Yh1x","outputId":"ea45992c-7dca-432e-86f8-8876b867c3be"},"source":["training_aug = numpy.zeros((len(total_training)*12, 128, 32)) # Dataset utilizzato per il training\n","index = 0\n","for vector_array in total_training:\n","  i = 0\n","  while (i+32) <= 313:\n","    vector_i = numpy.zeros((128,32))\n","    for j in range(0,128):\n","      vector_i[j] = vector_array[j][i:i+32]\n","    training_aug[index] = vector_i\n","    index += 1\n","    i = i+25\n","\n","validation_aug = numpy.zeros((len(total_validation)*12, 128, 32)) # Dataset utilizzato per il training\n","index = 0\n","for vector_array in total_validation:\n","  i = 0\n","  while (i+32) <= 313:\n","    vector_i = numpy.zeros((128,32))\n","    for j in range(0,128):\n","      vector_i[j] = vector_array[j][i:i+32]\n","    validation_aug[index] = vector_i\n","    index += 1\n","    i = i+25\n","\n","training_aug_transpose = numpy.zeros((len(training_aug), 32, 128))\n","index = 0\n","for elem in training_aug:\n","  training_aug_transpose[index] = elem.T\n","  index += 1\n","print(training_aug_transpose.shape)\n","\n","validation_aug_transpose = numpy.zeros((len(validation_aug), 32, 128))\n","index = 0\n","for elem in validation_aug:\n","  validation_aug_transpose[index] = elem.T\n","  index += 1\n","print(validation_aug_transpose.shape)\n","\n","\n","####### LABELS ######\n","# Associazione della label associata a ciascun spettrogramma a ciascuno dei frame estratto da esso.\n","training_labels = []\n","for elem in total_training_label:\n","  if numpy.array_equal(elem, numpy.asarray([1,0,0,0])) :\n","    for i in range(12):\n","      training_labels.append([1,0,0,0])\n","  elif numpy.array_equal(elem, numpy.asarray([0,1,0,0])):\n","    for i in range(12):\n","      training_labels.append([0,1,0,0])\n","  elif numpy.array_equal(elem, numpy.asarray([0,0,1,0])):\n","    for i in range(12):\n","      training_labels.append([0,0,1,0])\n","  elif numpy.array_equal(elem, numpy.asarray([0,0,0,1])):\n","    for i in range(12):\n","      training_labels.append([0,0,0,1])\n","\n","validation_labels = []\n","for elem in total_validation_label:\n","  if numpy.array_equal(elem, numpy.asarray([1,0,0,0])) :\n","    for i in range(12):\n","      validation_labels.append([1,0,0,0])\n","  elif numpy.array_equal(elem, numpy.asarray([0,1,0,0])):\n","    for i in range(12):\n","      validation_labels.append([0,1,0,0])\n","  elif numpy.array_equal(elem, numpy.asarray([0,0,1,0])):\n","    for i in range(12):\n","      validation_labels.append([0,0,1,0])\n","  elif numpy.array_equal(elem, numpy.asarray([0,0,0,1])):\n","    for i in range(12):\n","      validation_labels.append([0,0,0,1])\n","\n","training_labels = numpy.asarray(training_labels) # Dataset utilizzato per il training\n","validation_labels = numpy.asarray(validation_labels) # Dataset utilizzato per il training\n","#####################\n","\n","\n","####### CHOICES ######\n","# Associazione della choice associata a ciascun spettrogramma a ciascuno dei frame estratto da esso. \n","training_choices = []\n","for elem in total_training_choices:\n","  if numpy.array_equal(elem, numpy.asarray(\"match\")) :\n","    for i in range(12):\n","      training_choices.append(\"match\")\n","  elif numpy.array_equal(elem, numpy.asarray(\"non_match\")):\n","    for i in range(12):\n","      training_choices.append(\"non_match\")\n","\n","validation_choices = []\n","for elem in total_validation_choices:\n","  if numpy.array_equal(elem, numpy.asarray(\"match\")) :\n","    for i in range(12):\n","      validation_choices.append(\"match\")\n","  elif numpy.array_equal(elem, numpy.asarray(\"non_match\")):\n","    for i in range(12):\n","      validation_choices.append(\"non_match\")\n","\n","training_choices = numpy.asarray(training_choices) # Dataset utilizzato per il training\n","validation_choices = numpy.asarray(validation_choices) # Dataset utilizzato per il training\n","######################\n","\n","print(\"==== DATA ====\")\n","print(training_aug_transpose.shape)\n","print(validation_aug_transpose.shape)\n","\n","print(\"==== LABELS ====\")\n","print(training_labels.shape)\n","print(validation_labels.shape)\n","\n","print(\"==== CHOICES ====\")\n","print(training_choices.shape)\n","print(validation_choices.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(41880, 32, 128)\n","(2220, 32, 128)\n","==== DATA ====\n","(41880, 32, 128)\n","(2220, 32, 128)\n","==== LABELS ====\n","(41880, 4)\n","(2220, 4)\n","==== CHOICES ====\n","(41880,)\n","(2220,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UAsyVUTblaPA"},"source":["# KERAS MODEL DEFINITION"]},{"cell_type":"code","metadata":{"id":"ISWY6OjXbZNd","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4b3a42dc-6f20-4520-878a-913539c8aac7"},"source":["timesteps = 32\n","num_features = 128\n","\n","input_Spect = Input(shape = [timesteps, num_features])\n","input_Label = Input(shape = [4,])\n","\n","x = LSTM(64, \n","        batch_input_shape=(None, timesteps, num_features), \n","        return_sequences=True, name='encoder_1', \n","        kernel_constraint = max_norm(1), \n","        recurrent_constraint = max_norm(1), \n","        bias_constraint = max_norm(1))(input_Spect)\n","\n","x = LSTM(64, \n","        return_sequences=True, \n","        name='encoder_3', \n","        kernel_constraint = max_norm(1), \n","        recurrent_constraint = max_norm(1), \n","        bias_constraint = max_norm(1))(x)\n","\n","x = LSTM(16, \n","        return_sequences=False, \n","        name='encoder_4', \n","        kernel_constraint = max_norm(1), \n","        recurrent_constraint = max_norm(1), \n","        bias_constraint = max_norm(1))(x)\n","\n","# Second Branch - Conditioning Feed Forward Neural Network\n","m = Dense(16)(input_Label)\n","m = Activation('sigmoid')(m)\n","q = Dense(16)(input_Label)\n","\n","# Encoded Input Conditioning\n","m = Multiply()([x, m])\n","encoded_input_conditioned = Add()([q, m]) # Input da passare al decoder\n","\n","x = RepeatVector(timesteps, name='encoder_decoder_bridge')(encoded_input_conditioned)\n","\n","x = LSTM(16, \n","        return_sequences=True, name='decoder_1', \n","        kernel_constraint = max_norm(1), \n","        recurrent_constraint = max_norm(1), \n","        bias_constraint = max_norm(1))(x)\n","\n","x = LSTM(64, \n","        return_sequences=True, name='decoder_2', \n","        kernel_constraint = max_norm(1), \n","        recurrent_constraint = max_norm(1), \n","        bias_constraint = max_norm(1))(x)\n","\n","x = LSTM(64, \n","        return_sequences=True, name='decoder_3', \n","        kernel_constraint = max_norm(1), \n","        recurrent_constraint = max_norm(1), \n","        bias_constraint = max_norm(1))(x)\n","\n","x = TimeDistributed(Dense(num_features))(x)\n","\n","loss_tracker = keras.metrics.Mean(name=\"loss\")\n","mse_metric = keras.metrics.MeanSquaredError(name=\"mse\")\n","\n","class CustomModel(tensorflow.keras.Model):\n","    @property\n","    def metrics(self):\n","        return [loss_tracker, mse_metric]\n","\n","    def test_step(self, data):\n","        # Unpack the data\n","        x, y = data\n","        # Compute predictions\n","        y_pred = self([x[0],x[1]], training=False)\n","        # Indici match\n","        match = tf.where ( tf.equal(x[2][:], \"match\") )\n","        # Dati match\n","        data_match = K.gather(y, match)\n","        # Separazione dei dati PREDETTI sulla base degli indici relativi a match/non_match\n","        # Dati match\n","        pred_match = K.gather(y_pred, match)\n","\n","        # Update metrica\n","        mse_metric.update_state(data_match, pred_match)\n","\n","        return {\"mse\": mse_metric.result()}\n","    \n","    def train_step(self, data):\n","          # Unpack the data. Its structure depends on your model and on what you pass to `fit()`.\n","          x, y = data\n","\n","          # Vettore C utilizzato per il calcolo della loss in caso di non_match\n","          C = 5 \n","          # Valore di probabilità utilizzato come peso\n","          ALPHA = 0.75 \n","\n","          # Indici match\n","          match = tf.where ( tf.equal(x[2][:], \"match\") )\n","\n","          # Indici non_match\n","          not_match = tf.where ( tf.equal(x[2][:], \"non_match\") )\n","\n","          # Dati match\n","          data_match = K.gather(y, match)\n","\n","          with tf.GradientTape() as tape:\n","              y_pred = self([x[0],x[1]], training=True)  # Forward pass\n","\n","              # Separazione dei dati PREDETTI sulla base degli indici relativi a match/non_match\n","              # Dati match\n","              pred_match = K.gather(y_pred, match)\n","              # Dati non match\n","              pred_not_match = K.gather(y_pred, not_match) \n","\n","              loss_m = K.mean(keras.losses.mean_squared_error(data_match, pred_match)) + 1e-6  # Calcolo Loss Match\n","              loss_nm = K.mean(keras.losses.mean_squared_error(C,pred_not_match)) + 1e-6     # Calcolo Loss Non_Match\n","\n","              loss = ALPHA * loss_m + (1 - ALPHA) * loss_nm     # loss utilizzata per l'update dei pesi\n","\n","          # Compute gradients\n","          trainable_vars = self.trainable_variables\n","          gradients = tape.gradient(loss, trainable_vars)\n","\n","          # Update weights\n","          self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n","\n","          # Compute our own metrics\n","          loss_tracker.update_state(loss)\n","          mse_metric.update_state(y, y_pred)\n","          return {\"loss\": loss_tracker.result(), \"mse\": mse_metric.result()}\n","\n","model = CustomModel(inputs=(input_Spect, input_Label), outputs = x)\n","#opt = keras.optimizers.RMSprop(learning_rate = 0.0001)\n","model.compile(metrics=[\"mse\"], optimizer = \"adam\")\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"custom_model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            [(None, 32, 128)]    0                                            \n","__________________________________________________________________________________________________\n","input_4 (InputLayer)            [(None, 4)]          0                                            \n","__________________________________________________________________________________________________\n","encoder_1 (LSTM)                (None, 32, 64)       49408       input_3[0][0]                    \n","__________________________________________________________________________________________________\n","encoder_3 (LSTM)                (None, 32, 64)       33024       encoder_1[0][0]                  \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 16)           80          input_4[0][0]                    \n","__________________________________________________________________________________________________\n","encoder_4 (LSTM)                (None, 16)           5184        encoder_3[0][0]                  \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 16)           0           dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 16)           80          input_4[0][0]                    \n","__________________________________________________________________________________________________\n","multiply_1 (Multiply)           (None, 16)           0           encoder_4[0][0]                  \n","                                                                 activation_1[0][0]               \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 16)           0           dense_4[0][0]                    \n","                                                                 multiply_1[0][0]                 \n","__________________________________________________________________________________________________\n","encoder_decoder_bridge (RepeatV (None, 32, 16)       0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","decoder_1 (LSTM)                (None, 32, 16)       2112        encoder_decoder_bridge[0][0]     \n","__________________________________________________________________________________________________\n","decoder_2 (LSTM)                (None, 32, 64)       20736       decoder_1[0][0]                  \n","__________________________________________________________________________________________________\n","decoder_3 (LSTM)                (None, 32, 64)       33024       decoder_2[0][0]                  \n","__________________________________________________________________________________________________\n","time_distributed_1 (TimeDistrib (None, 32, 128)      8320        decoder_3[0][0]                  \n","==================================================================================================\n","Total params: 151,968\n","Trainable params: 151,968\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mbvCY_H6hDZA","outputId":"aeba976c-14af-4826-c0a4-8fb002b6c09d"},"source":["history = model.fit([training_aug_transpose, training_labels, training_choices],\n","                    training_aug_transpose, \n","                    epochs=100, \n","                    validation_data=([validation_aug_transpose, validation_labels, validation_choices], validation_aug_transpose), \n","                    batch_size=256)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","164/164 [==============================] - 14s 36ms/step - loss: 5.3414 - mse: 1.7391 - val_mse: 1.8476\n","Epoch 2/100\n","164/164 [==============================] - 4s 26ms/step - loss: 5.0305 - mse: 1.8834 - val_mse: 1.8722\n","Epoch 3/100\n","164/164 [==============================] - 4s 24ms/step - loss: 5.0255 - mse: 1.8914 - val_mse: 1.8712\n","Epoch 4/100\n","164/164 [==============================] - 4s 25ms/step - loss: 5.0225 - mse: 1.8978 - val_mse: 1.8656\n","Epoch 5/100\n","164/164 [==============================] - 4s 25ms/step - loss: 5.0195 - mse: 1.8986 - val_mse: 1.7842\n","Epoch 6/100\n","164/164 [==============================] - 4s 24ms/step - loss: 5.0173 - mse: 1.8960 - val_mse: 1.8127\n","Epoch 7/100\n","164/164 [==============================] - 4s 23ms/step - loss: 5.0168 - mse: 1.8971 - val_mse: 1.8419\n","Epoch 8/100\n","164/164 [==============================] - 4s 24ms/step - loss: 4.7789 - mse: 2.1201 - val_mse: 2.0688\n","Epoch 9/100\n","164/164 [==============================] - 4s 25ms/step - loss: 4.6312 - mse: 2.3534 - val_mse: 1.8644\n","Epoch 10/100\n","164/164 [==============================] - 4s 23ms/step - loss: 4.9733 - mse: 1.9504 - val_mse: 2.1805\n","Epoch 11/100\n","164/164 [==============================] - 4s 25ms/step - loss: 5.0234 - mse: 1.9113 - val_mse: 1.8630\n","Epoch 12/100\n","164/164 [==============================] - 4s 27ms/step - loss: 5.0173 - mse: 1.8971 - val_mse: 1.8327\n","Epoch 13/100\n","164/164 [==============================] - 4s 23ms/step - loss: 5.0138 - mse: 1.8993 - val_mse: 1.8632\n","Epoch 14/100\n","164/164 [==============================] - 4s 24ms/step - loss: 4.5886 - mse: 2.2685 - val_mse: 1.5257\n","Epoch 15/100\n","164/164 [==============================] - 4s 25ms/step - loss: 3.0794 - mse: 3.7916 - val_mse: 0.9883\n","Epoch 16/100\n","164/164 [==============================] - 4s 23ms/step - loss: 2.5575 - mse: 4.2269 - val_mse: 0.8238\n","Epoch 17/100\n","164/164 [==============================] - 4s 25ms/step - loss: 2.4085 - mse: 4.4417 - val_mse: 0.6640\n","Epoch 18/100\n","164/164 [==============================] - 4s 24ms/step - loss: 2.3451 - mse: 4.4903 - val_mse: 0.5794\n","Epoch 19/100\n","164/164 [==============================] - 4s 24ms/step - loss: 2.2703 - mse: 4.5772 - val_mse: 0.9500\n","Epoch 20/100\n","164/164 [==============================] - 4s 24ms/step - loss: 1.9745 - mse: 4.8540 - val_mse: 0.6010\n","Epoch 21/100\n","164/164 [==============================] - 4s 26ms/step - loss: 2.1014 - mse: 4.7500 - val_mse: 0.6778\n","Epoch 22/100\n","164/164 [==============================] - 4s 24ms/step - loss: 1.5989 - mse: 5.2182 - val_mse: 0.4909\n","Epoch 23/100\n","164/164 [==============================] - 4s 24ms/step - loss: 1.4693 - mse: 5.3812 - val_mse: 0.5468\n","Epoch 24/100\n","164/164 [==============================] - 4s 23ms/step - loss: 1.3764 - mse: 5.4630 - val_mse: 0.6222\n","Epoch 25/100\n","164/164 [==============================] - 4s 26ms/step - loss: 1.3790 - mse: 5.4536 - val_mse: 0.4338\n","Epoch 26/100\n","164/164 [==============================] - 4s 25ms/step - loss: 1.9863 - mse: 4.9237 - val_mse: 0.9174\n","Epoch 27/100\n","164/164 [==============================] - 4s 25ms/step - loss: 1.8830 - mse: 4.8962 - val_mse: 0.5858\n","Epoch 28/100\n","164/164 [==============================] - 4s 24ms/step - loss: 1.4103 - mse: 5.4180 - val_mse: 0.4809\n","Epoch 29/100\n","164/164 [==============================] - 4s 24ms/step - loss: 1.3298 - mse: 5.5051 - val_mse: 0.4322\n","Epoch 30/100\n","164/164 [==============================] - 4s 23ms/step - loss: 1.3583 - mse: 5.4627 - val_mse: 0.4148\n","Epoch 31/100\n","164/164 [==============================] - 4s 23ms/step - loss: 1.3215 - mse: 5.5261 - val_mse: 0.3981\n","Epoch 32/100\n","164/164 [==============================] - 4s 24ms/step - loss: 1.4285 - mse: 5.3948 - val_mse: 0.4371\n","Epoch 33/100\n","164/164 [==============================] - 4s 24ms/step - loss: 1.3132 - mse: 5.5261 - val_mse: 0.4550\n","Epoch 34/100\n","164/164 [==============================] - 4s 24ms/step - loss: 1.2712 - mse: 5.5516 - val_mse: 0.4806\n","Epoch 35/100\n","164/164 [==============================] - 4s 25ms/step - loss: 1.2510 - mse: 5.5653 - val_mse: 0.5912\n","Epoch 36/100\n","164/164 [==============================] - 4s 27ms/step - loss: 1.2613 - mse: 5.5593 - val_mse: 0.4224\n","Epoch 37/100\n","164/164 [==============================] - 4s 27ms/step - loss: 1.2450 - mse: 5.5717 - val_mse: 0.4033\n","Epoch 38/100\n","164/164 [==============================] - 4s 23ms/step - loss: 1.2552 - mse: 5.5545 - val_mse: 0.4010\n","Epoch 39/100\n","164/164 [==============================] - 4s 26ms/step - loss: 1.2270 - mse: 5.5918 - val_mse: 0.4666\n","Epoch 40/100\n","164/164 [==============================] - 4s 24ms/step - loss: 1.0535 - mse: 5.7433 - val_mse: 0.6149\n","Epoch 41/100\n","164/164 [==============================] - 4s 26ms/step - loss: 0.7480 - mse: 6.0657 - val_mse: 0.4616\n","Epoch 42/100\n","164/164 [==============================] - 4s 26ms/step - loss: 0.4844 - mse: 6.3000 - val_mse: 0.3127\n","Epoch 43/100\n","164/164 [==============================] - 4s 24ms/step - loss: 0.4283 - mse: 6.3715 - val_mse: 0.3881\n","Epoch 44/100\n","164/164 [==============================] - 4s 25ms/step - loss: 0.3709 - mse: 6.4083 - val_mse: 0.2890\n","Epoch 45/100\n","164/164 [==============================] - 4s 26ms/step - loss: 0.3941 - mse: 6.4057 - val_mse: 0.3721\n","Epoch 46/100\n","164/164 [==============================] - 4s 25ms/step - loss: 0.3124 - mse: 6.4518 - val_mse: 0.3227\n","Epoch 47/100\n","164/164 [==============================] - 4s 26ms/step - loss: 0.3564 - mse: 6.4158 - val_mse: 0.3335\n","Epoch 48/100\n","164/164 [==============================] - 4s 27ms/step - loss: 0.3923 - mse: 6.3869 - val_mse: 0.3552\n","Epoch 49/100\n","164/164 [==============================] - 4s 24ms/step - loss: 0.2860 - mse: 6.4753 - val_mse: 0.3069\n","Epoch 50/100\n","164/164 [==============================] - 4s 24ms/step - loss: 0.2418 - mse: 6.4982 - val_mse: 0.2834\n","Epoch 51/100\n","164/164 [==============================] - 4s 26ms/step - loss: 0.2467 - mse: 6.4859 - val_mse: 0.3255\n","Epoch 52/100\n","164/164 [==============================] - 4s 26ms/step - loss: 0.2420 - mse: 6.4803 - val_mse: 0.3160\n","Epoch 53/100\n","164/164 [==============================] - 4s 26ms/step - loss: 0.2295 - mse: 6.5005 - val_mse: 0.3390\n","Epoch 54/100\n","164/164 [==============================] - 4s 27ms/step - loss: 0.2055 - mse: 6.5078 - val_mse: 0.2890\n","Epoch 55/100\n","164/164 [==============================] - 4s 25ms/step - loss: 0.2078 - mse: 6.5120 - val_mse: 0.2590\n","Epoch 56/100\n","164/164 [==============================] - 4s 24ms/step - loss: 0.1976 - mse: 6.5087 - val_mse: 0.2553\n","Epoch 57/100\n","164/164 [==============================] - 4s 27ms/step - loss: 0.2976 - mse: 6.4422 - val_mse: 0.3261\n","Epoch 58/100\n","164/164 [==============================] - 4s 26ms/step - loss: 0.2436 - mse: 6.4676 - val_mse: 0.2320\n","Epoch 59/100\n","164/164 [==============================] - 5s 28ms/step - loss: 0.2233 - mse: 6.4911 - val_mse: 0.2637\n","Epoch 60/100\n","164/164 [==============================] - 4s 25ms/step - loss: 0.2020 - mse: 6.5042 - val_mse: 0.2613\n","Epoch 61/100\n","164/164 [==============================] - 4s 25ms/step - loss: 0.1941 - mse: 6.5164 - val_mse: 0.2398\n","Epoch 62/100\n","164/164 [==============================] - 4s 25ms/step - loss: 0.2235 - mse: 6.4801 - val_mse: 0.2472\n","Epoch 63/100\n","164/164 [==============================] - 4s 25ms/step - loss: 0.1913 - mse: 6.5104 - val_mse: 0.3842\n","Epoch 64/100\n","164/164 [==============================] - 4s 24ms/step - loss: 0.2667 - mse: 6.4447 - val_mse: 0.2828\n","Epoch 65/100\n","164/164 [==============================] - 5s 28ms/step - loss: 0.1776 - mse: 6.5221 - val_mse: 0.2788\n","Epoch 66/100\n","164/164 [==============================] - 5s 28ms/step - loss: 0.1860 - mse: 6.5152 - val_mse: 0.2931\n","Epoch 67/100\n","164/164 [==============================] - 4s 24ms/step - loss: 0.1853 - mse: 6.5177 - val_mse: 0.2581\n","Epoch 68/100\n","164/164 [==============================] - 4s 25ms/step - loss: 0.2207 - mse: 6.4805 - val_mse: 0.2221\n","Epoch 69/100\n","164/164 [==============================] - 4s 26ms/step - loss: 0.1715 - mse: 6.5290 - val_mse: 0.2076\n","Epoch 70/100\n","164/164 [==============================] - 4s 26ms/step - loss: 0.1617 - mse: 6.5358 - val_mse: 0.3208\n","Epoch 71/100\n","164/164 [==============================] - 4s 25ms/step - loss: 0.1758 - mse: 6.5171 - val_mse: 0.3159\n","Epoch 72/100\n","164/164 [==============================] - 4s 24ms/step - loss: 0.2673 - mse: 6.4388 - val_mse: 0.2019\n","Epoch 73/100\n","164/164 [==============================] - 4s 24ms/step - loss: 0.1867 - mse: 6.5127 - val_mse: 0.2295\n","Epoch 74/100\n","164/164 [==============================] - 4s 24ms/step - loss: 0.1573 - mse: 6.5365 - val_mse: 0.2413\n","Epoch 75/100\n","164/164 [==============================] - 4s 27ms/step - loss: 0.1849 - mse: 6.5087 - val_mse: 0.2099\n","Epoch 76/100\n","164/164 [==============================] - 4s 25ms/step - loss: 0.1702 - mse: 6.5230 - val_mse: 0.2352\n","Epoch 77/100\n","164/164 [==============================] - 4s 26ms/step - loss: 0.3362 - mse: 6.3824 - val_mse: 0.3716\n","Epoch 78/100\n","164/164 [==============================] - 4s 25ms/step - loss: 0.2007 - mse: 6.5114 - val_mse: 0.2679\n","Epoch 79/100\n","164/164 [==============================] - 4s 24ms/step - loss: 0.1740 - mse: 6.5168 - val_mse: 0.2389\n","Epoch 80/100\n","164/164 [==============================] - 4s 25ms/step - loss: 0.1779 - mse: 6.5151 - val_mse: 0.2645\n","Epoch 81/100\n","164/164 [==============================] - 4s 26ms/step - loss: 0.1562 - mse: 6.5303 - val_mse: 0.2416\n","Epoch 82/100\n","164/164 [==============================] - 4s 26ms/step - loss: 0.1882 - mse: 6.5066 - val_mse: 0.2922\n","Epoch 83/100\n","164/164 [==============================] - 4s 25ms/step - loss: 0.1713 - mse: 6.5188 - val_mse: 0.2815\n","Epoch 84/100\n","164/164 [==============================] - 5s 28ms/step - loss: 0.1612 - mse: 6.5234 - val_mse: 0.2490\n","Epoch 85/100\n","164/164 [==============================] - 4s 26ms/step - loss: 0.1613 - mse: 6.5221 - val_mse: 0.2979\n","Epoch 86/100\n","164/164 [==============================] - 4s 26ms/step - loss: 0.1531 - mse: 6.5316 - val_mse: 0.2816\n","Epoch 87/100\n","164/164 [==============================] - 4s 27ms/step - loss: 0.2211 - mse: 6.4763 - val_mse: 0.3082\n","Epoch 88/100\n","164/164 [==============================] - 4s 26ms/step - loss: 0.1868 - mse: 6.5035 - val_mse: 0.2372\n","Epoch 89/100\n","164/164 [==============================] - 4s 27ms/step - loss: 0.1588 - mse: 6.5252 - val_mse: 0.3229\n","Epoch 90/100\n","164/164 [==============================] - 4s 25ms/step - loss: 0.1836 - mse: 6.5107 - val_mse: 0.2831\n","Epoch 91/100\n","164/164 [==============================] - 4s 25ms/step - loss: 0.1750 - mse: 6.5043 - val_mse: 0.2627\n","Epoch 92/100\n","164/164 [==============================] - 5s 28ms/step - loss: 0.1728 - mse: 6.5179 - val_mse: 0.2439\n","Epoch 93/100\n","164/164 [==============================] - 4s 27ms/step - loss: 0.1527 - mse: 6.5294 - val_mse: 0.3115\n","Epoch 94/100\n","164/164 [==============================] - 4s 25ms/step - loss: 0.1745 - mse: 6.5068 - val_mse: 0.2090\n","Epoch 95/100\n","164/164 [==============================] - 4s 26ms/step - loss: 0.1520 - mse: 6.5299 - val_mse: 0.2532\n","Epoch 96/100\n","164/164 [==============================] - 4s 24ms/step - loss: 0.2501 - mse: 6.4765 - val_mse: 0.2555\n","Epoch 97/100\n","164/164 [==============================] - 4s 26ms/step - loss: 0.1706 - mse: 6.5263 - val_mse: 0.4262\n","Epoch 98/100\n","164/164 [==============================] - 4s 25ms/step - loss: 0.2138 - mse: 6.4783 - val_mse: 0.2858\n","Epoch 99/100\n","164/164 [==============================] - 4s 25ms/step - loss: 0.3609 - mse: 6.3496 - val_mse: 0.3110\n","Epoch 100/100\n","164/164 [==============================] - 4s 25ms/step - loss: 0.1520 - mse: 6.5335 - val_mse: 0.2484\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lZ8P46b6tq11"},"source":["model.save('/content/drive/MyDrive/models/fan/LSTM/model_fan.h5') "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"so_cAj-Ro0Ti"},"source":["with open('/content/drive/MyDrive/models/fan/LSTM/trainHistoryDict', 'wb') as file_pi:\n","    pickle.dump(history.history, file_pi)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TEtzqLn2liwP"},"source":["# TESTING"]},{"cell_type":"code","metadata":{"id":"y42D3ejetbrN"},"source":["import csv\n","\n","def save_csv(save_file_path,\n","             save_data):\n","    with open(save_file_path, \"w\", newline=\"\") as f:\n","        writer = csv.writer(f, lineterminator='\\n')\n","        writer.writerows(save_data)\n","\n","\n","# load dataset\n","def select_dirs(path):\n","    dir_path = os.path.abspath(path)\n","    dirs = sorted(glob.glob(dir_path))\n","    return dirs\n","\n","def file_load(wav_name, mono=False):\n","    try:\n","        return librosa.load(wav_name, sr=None, mono=mono)\n","    except:\n","        logger.error(\"file_broken or not exists!! : {}\".format(wav_name))\n","\n","def file_list_generator(target_dir, dir_name=\"train\", ext=\"wav\"):\n","    print(\"target_dir : {}\".format(target_dir))\n","\n","    # generate training list\n","    training_list_path = os.path.abspath(\"{dir}/{dir_name}/*.{ext}\".format(dir=target_dir, dir_name=dir_name, ext=ext))\n","    files = sorted(glob.glob(training_list_path))\n","    if len(files) == 0:\n","      print(\"errore\")\n","    return files\n","\n","\n","def file_to_vector_array(file_name, n_mels=64, n_fft=1024, hop_length=512, power=2.0):\n","    # 02 generate melspectrogram using librosa\n","    y, sr = file_load(file_name)\n","    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels, power=power)\n","\n","    # 03 convert melspectrogram to log mel energy\n","    log_mel_spectrogram = 20.0 / power * numpy.log10(mel_spectrogram + sys.float_info.epsilon)\n","\n","    return log_mel_spectrogram\n","\n","  \n","def list_to_vector_array(file_list, msg=\"calc...\", n_mels=64, n_fft=1024, hop_length=512, power=2.0, frames=10):\n","    # iterate file_to_vector_array()\n","    for idx in tqdm(range(len(file_list)), desc=msg):\n","        vector_array = file_to_vector_array(file_list[idx], n_mels=n_mels, n_fft=n_fft, hop_length=hop_length, power=power)\n","\n","        if idx == 0:\n","            dataset = numpy.zeros((len(file_list), n_mels, frames), float)\n","        dataset[vector_array.shape[0] * idx: vector_array.shape[0] * (idx + 1), :] = vector_array\n","    return dataset\n","\n","def key_by_id(item):\n","  path_splitted = item.split(\"/\")\n","  file_name = path_splitted[ len(path_splitted) - 1 ]\n","  file_name_splitted = file_name.split(\"_\")\n","  machine_id = file_name_splitted = file_name_splitted[2]\n","  return machine_id\n","\n","def get_machine_id_list_for_test(target_dir,\n","                                 dir_name=\"test\",\n","                                 ext=\"wav\"):\n","\n","    # create test files\n","    dir_path = os.path.abspath(\"{dir}/{dir_name}/*.{ext}\".format(dir=target_dir, dir_name=dir_name, ext=ext))\n","    file_paths = sorted(glob.glob(dir_path))\n","    # extract id\n","    machine_id_list = sorted(list(set(itertools.chain.from_iterable(\n","        [re.findall('id_[0-9][0-9]', ext_id) for ext_id in file_paths]))))\n","    return machine_id_list\n","\n","def test_file_list_generator(target_dir,\n","                             id_name,\n","                             dir_name=\"test\",\n","                             prefix_normal=\"normal\",\n","                             prefix_anomaly=\"anomaly\",\n","                             ext=\"wav\"):\n","  \n","    print(\"target_dir : {}\".format(target_dir+\"_\"+id_name))\n","\n","    normal_files = sorted(\n","    glob.glob(\"{dir}/{dir_name}/{prefix_normal}_{id_name}*.{ext}\".format(dir=target_dir,\n","                                                                                 dir_name=dir_name,\n","                                                                                 prefix_normal=prefix_normal,\n","                                                                                 id_name=id_name,\n","                                                                                 ext=ext)))\n","    normal_labels = numpy.zeros(len(normal_files))\n","    anomaly_files = sorted(\n","    glob.glob(\"{dir}/{dir_name}/{prefix_anomaly}_{id_name}*.{ext}\".format(dir=target_dir,\n","                                                                                  dir_name=dir_name,\n","                                                                                  prefix_anomaly=prefix_anomaly,\n","                                                                                  id_name=id_name,\n","                                                                                  ext=ext)))\n","    anomaly_labels = numpy.ones(len(anomaly_files))\n","    files = numpy.concatenate((normal_files, anomaly_files), axis=0)\n","    labels = numpy.concatenate((normal_labels, anomaly_labels), axis=0)\n","    print(\"test_file  num : {num}\".format(num=len(files)))\n","    if len(files) == 0:\n","        print(\"no_wav_file!!\")\n","    print(\"\\n========================================\")\n","\n","    return files, labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jQLl5W5n7_T5","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d6bd2e6f-db00-455b-e5bb-24f2d90ebbc7"},"source":["target_dir = \"/content/drive/MyDrive/test/fan\"\n","\n","machine_type = os.path.split(target_dir)[1]\n","print(\"============== MODEL LOAD ==============\")\n","# set model path\n","model_file = \"/content/drive/MyDrive/models/fan/LSTM/model_fan.h5\"\n","\n","# load model file\n","if not os.path.exists(model_file):\n","  print(\"{} model not found \".format(machine_type))\n","  sys.exit(-1)\n","model = keras.models.load_model(model_file, custom_objects={'CustomModel': CustomModel, 'mse':mse_metric})\n","# model.summary()\n","\n","machine_id_list = get_machine_id_list_for_test(target_dir)\n","\n","# initialize lines in csv for AUC and pAUC\n","csv_lines = []\n","\n","csv_lines.append([machine_type])\n","csv_lines.append([\"id\", \"AUC\", \"pAUC\"])\n","performance = []\n","\n","for id_str in machine_id_list:\n","  # load test file\n","\n","  id_num = id_str.split(\"_\")[1]\n","\n","  # Definizione della label \"match\" da utilizzare in fase di testing e del min e max da utilizzare per la normalizzazione\n","  # i min e max sono stati calcolati a partire dai dati di training.\n","  if id_num == \"00\":\n","    match_labels = numpy.asarray([1,0,0,0])\n","    mean = mean_00\n","    std = std_00\n","  if id_num == \"02\":\n","    match_labels = numpy.asarray([0,1,0,0])\n","    mean = mean_02\n","    std = std_02\n","  if id_num == \"04\":\n","    match_labels = numpy.asarray([0,0,1,0])\n","    mean = mean_04\n","    std = std_04\n","  if id_num == \"06\":\n","    match_labels = numpy.asarray([0,0,0,1])\n","    mean = mean_06\n","    std = std_06\n","\n","  test_files, y_true = test_file_list_generator(target_dir, id_str)\n","\n","  # setup anomaly score file path\n","  anomaly_score_csv = \"/content/drive/MyDrive/models/fan/LSTM/anomaly_score_{machine_type}_{id_str}.csv\".format(machine_type=machine_type, id_str=id_str)\n","  anomaly_score_list = []\n","\n","  print(\"\\n============== BEGIN TEST FOR A MACHINE ID {id} ==============\".format(id=id_num))\n","\n","  y_pred = [0. for k in test_files]\n","\n","  for file_idx, file_path in tqdm(enumerate(test_files), total=len(test_files)):\n","\n","    # Estrazione spettrogramma audio test\n","    data = file_to_vector_array(file_path, n_mels=N_MELS, n_fft=N_FFT, hop_length=HOP_LENGTH, power=POWER)\n","    # Normalizzazione spettrogramma di test\n","    data = ( data - mean ) / (std)\n","\n","    #print(data_aug_transpose.shape)\n","\n","    data_aug = numpy.zeros((12, 128, 32))\n","    index = 0\n","    i = 0\n","    while (i+32) <= 313:\n","      vector_i = numpy.zeros((128,32))\n","      for j in range(0,128):\n","        vector_i[j] = data[j][i:i+32]\n","      data_aug[index] = vector_i\n","      index += 1\n","      i = i+25\n","\n","    data_aug_transpose = numpy.zeros((len(data_aug), 32, 128))\n","    index = 0\n","    for elem in data_aug:\n","      data_aug_transpose[index] = elem.T\n","      index += 1\n","    #print(data_aug_transpose.shape)\n","    \n","    # Calcolo dell'errore medio sulle frame estratte dallo spettrogramma\n","    elem_error = []\n","    for elem in data_aug_transpose:\n","      predicted = model.predict([elem.reshape(1,32,128), match_labels.reshape(1,4)])\n","      errors = numpy.mean(numpy.square(elem - predicted), axis=1)\n","      elem_error.append(numpy.mean(errors))\n","\n","    # Log dell'errore associato all'istanza di test\n","    y_pred[file_idx] = numpy.mean(errors)\n","    anomaly_score_list.append([os.path.basename(file_path), y_pred[file_idx]])\n","  \n","  save_csv(save_file_path=anomaly_score_csv, save_data=anomaly_score_list)\n","    \n","  # Calcolo AUC e pAUC per i dati con un certo ID_0x\n","  auc = metrics.roc_auc_score(y_true, y_pred)\n","  p_auc = metrics.roc_auc_score(y_true, y_pred, max_fpr=0.1)\n","  csv_lines.append([id_str.split(\"_\", 1)[1], auc, p_auc])\n","  performance.append([auc, p_auc])\n","  print(\"AUC : {}\".format(auc))\n","  print(\"pAUC : {}\".format(p_auc))\n","\n","  print(\"\\n============ END OF TEST FOR A MACHINE ID ============\")\n","\n","# Stampa di AUC e pAUC medi su tutti i dati di test (media di AUC e pAUC sui vari ID).\n","print(\"\\n============ AVERAGE PERFORMANCES ============\")\n","averaged_performance = numpy.mean(numpy.array(performance, dtype=float), axis=0)\n","csv_lines.append([\"Average\"] + list(averaged_performance))\n","csv_lines.append([])\n","print(averaged_performance)\n","\n","result_path = \"/content/drive/MyDrive/models/fan/LSTM/anomaly_score_avg.csv\"\n","save_csv(save_file_path=result_path, save_data=csv_lines)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["============== MODEL LOAD ==============\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/507 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["target_dir : /content/drive/MyDrive/test/fan_id_00\n","test_file  num : 507\n","\n","========================================\n","\n","============== BEGIN TEST FOR A MACHINE ID 00 ==============\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 507/507 [04:43<00:00,  1.79it/s]\n","  0%|          | 0/459 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["AUC : 0.5136363636363637\n","pAUC : 0.4907539118065434\n","\n","============ END OF TEST FOR A MACHINE ID ============\n","target_dir : /content/drive/MyDrive/test/fan_id_02\n","test_file  num : 459\n","\n","========================================\n","\n","============== BEGIN TEST FOR A MACHINE ID 02 ==============\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 459/459 [04:19<00:00,  1.77it/s]\n","  0%|          | 0/448 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["AUC : 0.8221727019498607\n","pAUC : 0.7616185310071837\n","\n","============ END OF TEST FOR A MACHINE ID ============\n","target_dir : /content/drive/MyDrive/test/fan_id_04\n","test_file  num : 448\n","\n","========================================\n","\n","============== BEGIN TEST FOR A MACHINE ID 04 ==============\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 448/448 [04:14<00:00,  1.76it/s]\n","  0%|          | 0/461 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["AUC : 0.5947413793103448\n","pAUC : 0.5936176648517847\n","\n","============ END OF TEST FOR A MACHINE ID ============\n","target_dir : /content/drive/MyDrive/test/fan_id_06\n","test_file  num : 461\n","\n","========================================\n","\n","============== BEGIN TEST FOR A MACHINE ID 06 ==============\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 461/461 [04:15<00:00,  1.80it/s]"],"name":"stderr"},{"output_type":"stream","text":["AUC : 0.8812742382271468\n","pAUC : 0.8607668756378482\n","\n","============ END OF TEST FOR A MACHINE ID ============\n","\n","============ AVERAGE PERFORMANCES ============\n","[0.70295617 0.67668925]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]}]}